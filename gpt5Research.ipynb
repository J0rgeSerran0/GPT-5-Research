{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c02fdd4-284d-47c6-ac9b-87c59b46da7a",
   "metadata": {},
   "source": [
    "# GPT-5\n",
    "In this notebook, I will cover a quick look at some new capabilities and new features of GPT-5.\n",
    "\n",
    "This includes:\n",
    "+ New parameters - verbosity, reasoning effort, etc.\n",
    "+ Tools\n",
    "+ Simple online games\n",
    "+ Constraint satisfaction - summer scheduling, dog problem.  \n",
    "+ Image and text input modalities\n",
    "    + Navigation\n",
    "    + Counting\n",
    "+ Model router\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb20a90-65a4-4dc8-9f5d-8f850512ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Load env variables\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "azure_oai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_model_deployment = os.getenv(\"AZURE_MODEL_DEPLOYMENT\")\n",
    "azure_oai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "#api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "model_router = \"model-router\"\n",
    "\n",
    "# To use API key, set this to False.  \n",
    "use_entra_id = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63658539-faca-4413-8f62-18a5bfcc7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"az login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf339e-8f85-4cc3-9c4b-47ff6de634cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clients and helper methods\n",
    "responses_client = None\n",
    "chat_client = None\n",
    "\n",
    "if use_entra_id: \n",
    "    token_provider = get_bearer_token_provider(\n",
    "        DefaultAzureCredential(exclude_interactive_browser_credential=False), \"https://cognitiveservices.azure.com/.default\"\n",
    "    )\n",
    "    \n",
    "    responses_client = AzureOpenAI(\n",
    "        base_url=azure_oai_endpoint + \"openai/v1/\",\n",
    "        api_version=\"preview\",\n",
    "        azure_ad_token_provider=token_provider\n",
    "    )\n",
    "\n",
    "    chat_client = AzureOpenAI(\n",
    "        azure_endpoint=azure_oai_endpoint,\n",
    "        api_version=\"2025-04-01-preview\",\n",
    "        azure_ad_token_provider=token_provider\n",
    "    )\n",
    "else:\n",
    "    responses_client = AzureOpenAI(\n",
    "        base_url=azure_oai_endpoint + \"openai/v1/\",\n",
    "        api_version=\"preview\",\n",
    "        api_key=azure_oai_key\n",
    "    )\n",
    "    \n",
    "    chat_client = AzureOpenAI(\n",
    "        azure_endpoint=azure_oai_endpoint,\n",
    "        api_version=\"2025-04-01-preview\",\n",
    "        api_key=azure_oai_key\n",
    "    )\n",
    "\n",
    "\n",
    "def call_chat_completions_api(prompt, model = azure_model_deployment):    \n",
    "    response = chat_client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    print(response.model_dump_json(indent=2)) \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def call_model_router(prompt):    \n",
    "    response = chat_client.chat.completions.create(\n",
    "        model = model_router,\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    #print(response.model_dump_json(indent=2))\n",
    "    \n",
    "    # Extract the model value\n",
    "    print(\"Model used: \", response.model)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "    \n",
    "def call_model_router_with_image(prompt, image_url):   \n",
    "    response = chat_client.chat.completions.create(\n",
    "        model = model_router,\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"You are a helpful assistant.\" \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "    \t            {\n",
    "    \t                \"type\": \"text\",\n",
    "    \t                \"text\": prompt\n",
    "    \t            },\n",
    "    \t            {\n",
    "    \t                \"type\": \"image_url\",\n",
    "    \t                \"image_url\": {\n",
    "                            \"url\": image_url\n",
    "                        }\n",
    "                    } \n",
    "               ] \n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    #print(response.model_dump_json(indent=2))\n",
    "    \n",
    "    # Extract the model value\n",
    "    print(\"Model used: \", response.model)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def call_responses_api(prompt):\n",
    "    response = responses_client.responses.create(\n",
    "        model = azure_model_deployment,\n",
    "        input = prompt \n",
    "    )\n",
    "    #print(response.model_dump_json(indent=2)) \n",
    "    return response.output[1].content[0].text\n",
    "    \n",
    "\n",
    "def call_responses_api_with_image_url(prompt, image_url):\n",
    "    response = responses_client.responses.create(\n",
    "        model=azure_model_deployment,\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": prompt,\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"input_image\",\n",
    "                        \"image_url\": image_url\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    #print(response.output_text)\n",
    "    return response.output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ecc23-468d-4f2c-9141-0c8ae73afade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use both the responses API and the chat completions API with GPT-5.  \n",
    "answer = call_responses_api(\"How many b's are there in blueberry?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97ad17-2a0d-4e5d-898c-69eacbf73d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_chat_completions_api(\"How many r are there in strawberry?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d84117-8fa4-4934-af87-104b4e6f40a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some new parameters!  \n",
    "response = responses_client.responses.create(\n",
    "    input=\"Tell me about the curious case of neural text degeneration\",\n",
    "    model=azure_model_deployment,\n",
    "    reasoning={\n",
    "        \"effort\": \"medium\",\n",
    "        \"summary\": \"auto\" # auto, concise, or detailed \n",
    "    },\n",
    "    text={\n",
    "        \"verbosity\": \"low\" # New with GPT-5 models\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c56744-cc3e-43ba-ac01-8ff0be9ff0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New verbosity parameter\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.text import Text\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "def pretty_print(verbosity, tokens, output_text):\n",
    "    console = Console()\n",
    "    text = Text()\n",
    "    \n",
    "    # Print the verbosity in color\n",
    "    text.append(verbosity, style=\"bold magenta\")\n",
    "    text.append(f\" ({str(tokens)} tokens): \", style=\"magenta\")\n",
    "    console.print(text)\n",
    "    md = Markdown(output_text)\n",
    "    console.print(md)\n",
    "    console.print(\"\\n\")\n",
    "\n",
    "\n",
    "prompt = \"Write an emotional poem about a daughter leaving home for college.\"\n",
    "\n",
    "for verbosity in [\"low\", \"medium\", \"high\"]:\n",
    "    response = responses_client.responses.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        input=prompt,\n",
    "        text={\"verbosity\": verbosity}\n",
    "    )\n",
    "\n",
    "    # Extract text\n",
    "    output_text = \"\"\n",
    "    for item in response.output:\n",
    "        if hasattr(item, \"content\") and item.content != None:\n",
    "            for content in item.content:\n",
    "                if hasattr(content, \"text\"):\n",
    "                    output_text += content.text\n",
    "\n",
    "    usage = response.usage\n",
    "    pretty_print(verbosity, usage.output_tokens, output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c7e79-a2da-4c37-a524-381333374fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition of \"minimal\" reasoning effort\n",
    "\n",
    "prompt = \"Explain why the sky is blue, and how this explanation would change if Earth had a thicker atmosphere composed primarily of methane.\"\n",
    "\n",
    "for reasoning_effort in [\"minimal\", \"low\", \"medium\", \"high\"]:\n",
    "    response = responses_client.responses.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        input=prompt,\n",
    "        reasoning = {\n",
    "            \"effort\": reasoning_effort\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Extract text\n",
    "    output_text = \"\"\n",
    "    for item in response.output:\n",
    "        if hasattr(item, \"content\") and item.content != None:\n",
    "            for content in item.content:\n",
    "                if hasattr(content, \"text\"):\n",
    "                    output_text += content.text\n",
    "\n",
    "    usage = response.usage\n",
    "    pretty_print(reasoning_effort, usage.output_tokens, output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f10f1-113c-461b-9e1c-a76b8d9fa073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support for custom tools\n",
    "response = responses_client.responses.create(  \n",
    "    model=\"gpt-5\",  # replace with your model deployment name  \n",
    "    tools=[  \n",
    "        {  \n",
    "            \"type\": \"custom\",\n",
    "            \"name\": \"lark_tool\",\n",
    "            \"format\": {\n",
    "                \"type\": \"grammar\",\n",
    "                \"syntax\": \"lark\",\n",
    "                \"definition\": \"start: QUESTION NEWLINE ANSWER\\nQUESTION: /[^\\\\n?]{1,200}\\\\?/\\nNEWLINE: /\\\\n/\\nANSWER: /[^\\\\n!]{1,200}!/\"\n",
    "            }\n",
    "        }  \n",
    "    ],  \n",
    "    input=[{\"role\": \"user\", \"content\": \"Please calculate the area of a circle with radius equal to the number of 'r's in strawberry\"}],  \n",
    ")  \n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41d194-4090-4574-8117-f3bc70c681b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building games with good web frontend\n",
    "def write_to_file(filename, text):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "\n",
    "checkers_prompt = '''\n",
    "Create a playable game of checkers in a single page of html.  \n",
    "+ The checkers should be blue and pink.  Pink always goes first.  \n",
    "+ The human player should control the pink checkers.  You should write some simple logic for the blue player to always make a valid move.  \n",
    "+ Blue's turn should be taken immediately after pink moves the checker piece.  \n",
    "+ Give simple instructions to the user on how to move the pieces in the UI.  \n",
    "+ The UI should be clean and simple.  \n",
    "'''\n",
    "response = call_responses_api(checkers_prompt)\n",
    "print(response)\n",
    "\n",
    "num = \"1\"\n",
    "filename = \"checkers\" + num + \".html\"\n",
    "write_to_file(filename, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0712f7a5-07e4-4aa2-b1b7-10b05439381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "Create a playable game of Sudoku in a single page of html.  \n",
    "+ The difficulty level should be \"easy\". \n",
    "+ Include a way to write notes of possible options for the square, as well as a way to lock in the number that belongs there.  \n",
    "+ Include a \"reset\" button to start the game over and change the puzzle.  \n",
    "+ The UI should be clean and simple.  \n",
    "'''\n",
    "response = call_responses_api(prompt)\n",
    "print(response)\n",
    "\n",
    "filename = \"sudoku\" + num + \".html\"\n",
    "write_to_file(filename, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193d1df-de27-4b32-bebc-584fcfe4e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building quiz with good web frontend\n",
    "prompt = '''\n",
    "Create an online quiz in a single page of html.  \n",
    "+ The quiz should sort you into one of the 4 Hogwarts houses, based on your answers and the qualities of the students in each house.  \n",
    "+ The end user should be able to select answers from multiple choice answers.    \n",
    "+ There should be 10 questions.  After all 10 questions are answered, the webpage should tell you which house you are in with an appropriate graphic to celebrate.\n",
    "+ The UI should be clean and simple.  Include a scroll bar if the quiz is long enough to need it.  \n",
    "'''\n",
    "response = call_responses_api(prompt)\n",
    "print(response)\n",
    "\n",
    "filename = \"quiz\" + num + \".html\"\n",
    "write_to_file(filename, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79637ba7-b34e-4a5d-ad57-675ebf66940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tools to access data that isn't in training set\n",
    "# NOTE: this is using OpenAI and not Azure OpenAI.  AOAI doesn't have support for web search yet; reference: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/responses?tabs=python-secure\n",
    "\n",
    "from openai import OpenAI\n",
    "openai_client = OpenAI()\n",
    "\n",
    "prompt = \"What is the best song from K Pop Demon Hunters?  How does each song from the movie relate to the Hero's Journey?\"\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model=azure_model_deployment,\n",
    "    tools=[{\"type\": \"web_search_preview\"}],\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a77be8-8511-4faf-84d9-16d03113bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint satisfaction problem - dog medication scheduling\n",
    "prompt = '''\n",
    "Our dog Titan has to take 3 medications. He needs 10mg metoclopramide twice per day. He needs 1000mg carafate three times per day, \n",
    "but it can't be taken within 2 hours of metoclopramide. Finally, he needs 10mg omeprazole twice per day, and this can be taken with \n",
    "the metoclopramide. I need to sleep from midnight-7am. What is the best time to give the dog each medication?\n",
    "'''\n",
    "response = call_responses_api(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e5128-c3ce-4292-ae7f-975c162e82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image understanding with GPT-5 - OCR, spatial reasoning, color identification\n",
    "wordle_image_url = \"https://raw.githubusercontent.com/jennifermarsman/WordleGPT/main/images/Example9Step2.png\"\n",
    "wordle_prompt = \"What is a good next word to guess in this Wordle puzzle?\"\n",
    "result = call_responses_api_with_image_url(wordle_prompt, wordle_image_url)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b3768f-451a-4f2d-8f0d-db277975811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image understanding with GPT-5 - counting\n",
    "image_url = \"https://www.royalcourt.no/aim/kongehuset2/files/3/b/3/a61b9ba453c594ec72f0d7148795d5d6a9e5293f0e/3b3a61b9ba453c594ec72f0d7148795d5d6a9e5293f0e.jpg\"\n",
    "prompt = \"70 gifts are to be distributed equally among the people in the photo, and the remainder should be given to charity.  How many gifts will each person get?  How much is given to charity?\"\n",
    "result = call_responses_api_with_image_url(prompt, image_url)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264e719-9bf7-4d3e-b777-02753414eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image understanding with GPT-5 - blind scenario\n",
    "image_url = \"https://ey2msiqxj7z.exactdn.com/wp-content/uploads/2020/04/13162308/0120_Westerly_Reveal_6C_Kitchen_Alt_Angles_Lights_on_15-1-1024x683.jpg?strip=all&lossy=1&ssl=1\"\n",
    "prompt = \"I am blind and this is the view in front of me.  I want to prepare a snack of an apple with peanut butter and a glass of milk.  We keep the peanut butter in the pantry.  Give detailed instructions of how to navigate to do this.\"\n",
    "result = call_responses_api_with_image_url(prompt, image_url)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14138fae-65b7-48cd-8eb7-ba03725eaab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selector\n",
    "prompts = [\n",
    "    \"Hello\",\n",
    "    checkers_prompt\n",
    "]\n",
    "\n",
    "for each prompt in prompts:\n",
    "    reply = call_model_router(prompt)\n",
    "    print(reply)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ce729-9ed0-4f91-9af2-2e122835e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selector with image url\n",
    "\n",
    "# Simple example\n",
    "reply = call_model_router_with_image(\"Describe this image.\", \"https://media.licdn.com/dms/image/C4E12AQFuU9fEDEf6UQ/article-cover_image-shrink_600_2000/0/1520216049699?e=2147483647&v=beta&t=cVjZ9psohJpUcNKpgLX-ercyjYHOBHHW-dhVCsjuaHs\")\n",
    "print(reply)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Complex example\n",
    "reply = call_model_router_with_image(wordle_prompt, wordle_image_url)\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2504594-1462-4aa9-acfc-5420570b41ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
